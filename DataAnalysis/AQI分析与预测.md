#  数据分析与预测

## 1.  数据分析基本流程

- 明确需求与目的
- 数据集
  - 内部数据
  - 购买数据
  - 爬取数据
  - 调查问卷
  - 其他收集
- 数据预处理
  - 数据整合
    - 横向整合
    - 纵向整合
  - 数据清洗
    - 缺失值
    - 异常值
    - 重复值
  - 数据转换
  - 数据分析
    - 描述分析
    - 推断分析
    - 数据建模
      - 特征工程
      - 超参数调整
    - 数据可视化
  - 编写报告

## 2. 缺失值处理

1. 删除缺失值
   - 仅适合于缺失数据量很少的情况
2. 填充缺失值
   - 数值变量
     - 均值填充
     - 中值填充
   - 类别变量
     - 众数填充
     - 单独作为一个类别
   - 额外说明
     - 缺失值小于20%, 直接填充.
     - 缺失值在20%~80%, 填充变量后, 同时增加一列, 标记该列是否缺失, 参与后续建模.
     - 缺失值大于80%, 不用原始值, 而是增加一列, 标记该列是否缺失, 参与后续建模.

## 3. 异常值探索

### 3.1 探索异常值:

- 通过 describe 查看数值信息.
- $3 \sigma$方式
- 使用箱线图辅助.
- 相关异常检测算法.

### 3.2 异常值处理:

- 删除异常值

- 视为缺失值处理

- 对数变换

  > 取对数的 方式比较简单, 不过也存在一些局限:

  - 取对数智能针对正数操作. 不过我们可以通过如下的方式进行转换:

    $np.signo(X) * np.log(np.abs(X) +1)$

  - 适合右偏分布, 不适合左偏分布.

- 使用临界值填充

- 使用分箱法离散化处理

  > 有时候, 特征对目标值存在一定的影响, 但是, 这种影响可能未必是线性的增加, 此时, 我们就可以使用分箱方式, 对特征值进行离散化处理.

## 4. 重复值

### 4.1 重复值探索

- 使用 duplicate 检查重复值. 可配合keep 参数进行调整.

  ```python
  # keep: 'first', 'last', False 三个参数.表示不同标记方式
  df.duplocated(keep=False)
  ```

- 重复值对数据分析通常没有作用, 直接删除即可.

  ```python
  df.drop_duplicates(inplace=True)
  ```

# 5. 数据探索.

## 5.1 sns 的应用

- 直方图

  ```python
  # 数值类型: 图上会有小竖杠-----置信空间
  sns.barplot(x='colunm', y='label', data)
  ```

- 统计直方图

  ```python
  sns.countplot(x=data, order=labels)
  ```

- 地图分布图

  ```python
  sns.scatterplot(x='longitude', y='latitude', hue=label, data=data, palette=plt.cm.RdYlGn_r)
  ```

- 散点图

  ```python
  # 直方散点图
  sns.stripplot(x='colunm', y='label', data=data)
  # 分布散点图
  sns.swarmplot(x='colunm', y='label', data=data)
  ```

- 小提琴图

  ```python
  sns.violinplot(x='colunm', y='label', data)
  ```

- 箱线图

  ```python
  sns.boxplot(x='colunm', y='label', data)
  ```

- 散点+箱线图\小提琴图

  ```python
  # 精髓 inner
  sns.violinplot(x='colunm', y='label', data=data, inner=None)
  sns.swarmplot(x='colunm', y='label', data=data)
  ```

- 散点矩阵

  ```python
  sns.pairplot(data[['colunm_1','colunm_2']])
  ```

## 5.2 相关系数

### 5.2.1 协方差定义

设变量:
$$
X = (x_1, x_2, ..., x_n) \\ 
Y = (y_1, y_2, ..., y_n)
$$
这变量 $X$ 与 $Y$ 的协方差定义为:
$$
Cov(X, Y) = \frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n-1}
$$


> 协方差体现的是两个变量之间的分散性以及两个变量变化步调是否一致.
>
> 易得: 当协方差的两个变量相同时, 协方差就是方差.

### 5.2.2 相关系数定义

> 相关系数, 可以用来体现两个连续变量之间的相关性, 最为常用的为皮尔逊相关系数. 两个变量的相关系数定义为:

$$
r(X, Y) = \frac{Cov(X, y)}{\sigma_X\sigma_Y} \\
= \frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2\sum_{i=1}^n(y_i-\bar{y})^2}}
$$

- $\sigma_X$: 变量$X$ 的标准差

先关系数的取值范围为[-1, 1], 我们可以根据先关系数的取值来衡量两个变量的相关性:

- 0.8 - 1.0 : 极强先关
- 0.6 - 0.8:  强相关
- 0.4 - 0.6: 中等程度相关
- 0.2 - 0.4: 弱相关
- 0.0 - 0.2: 极弱相关或无相关

## 5.2.3 特征选择

> 特征并非越多越好, 有些特征可能对模型的质量并没有改善, 我们可以进行删除, 同时也能够提升模型的训练速度.

### 5.2.3.1 RFECV

> RFECV 分成两个部分, 分别是L

- RFE (Recursive feature elimination): 递归特征消除, 用来对特征进行重要性评级.
- CV(Cross Validation): 交叉验证, 在特征评级后, 通过交叉验证, 选择最佳数量的特征.

具体过程如下:

- PFE阶段

  1. 初始的特征集为所有可用的特征
  2. 使用当前特征进行建模, 然后计算每个特征的重要性.
  3. 删除最不重要的一个(或多个)特征, 更新特征集
  4. 跳转到步骤2, 直到完成说有特征的重要性评级.

- CV阶段

  1. 根据RFE阶段确定的特征重要性.
  2. 对选定的特征集进行交叉验证
  3. 确定平均分最高的特征数量, 完成特征选择.

  




**基础术语**

- **数据挖掘定义**

  > 数据挖掘: 起源与多个学科， 比如建模部分起源于统计学和机器学习。
  >
  > 统计学----以数据模型为驱动，常常建立一个能够产生数据的模型。
  >
  > 机器学习 --- 以算法为驱动，让计算机执行算法来发现知识， 自我学习。

- 数据挖掘是指正在大型的数据仓库张对有价值的信息知识进行获取，其方法一种是分类分析，一种是聚类.
  - 数据初期的准备通常占用整个数据挖掘项目工作的70%左右。
  - 数据挖掘本身融合了统计学， 数据库和机器学习等学科， 并不是新的技术。
  - 数据挖掘更适合业务人员来学习(相比技术人员学习业务来的更高效)
  - 数据挖掘适用于传统的BI(报表，OLAP等)无法支持的领域
- 数据挖掘工作领域大致分为三大类:
  - 数据分析师: 在拥有行业数据的电商, 金融, 电信, 咨询等行业做业务咨询, 商务智能, 分析报告.
  - 数据挖掘工程师: 在多媒体, 电商, 搜索, 社交等大数据相关行业做机器学习算法实现和分析.
  - 科学研究方向: 在高校, 科研单位, 企业研究院校等高大上科研机构研究算法效率改进以及未来应用.
  
- **数据挖掘的两个基本目标:**
 > - 预测数据   ---  监督学习(supervised learning) 其中包括 回归, 分类等算法
 > - 描述数据   ---  无监督学习(unsupervised learning) 其中包括 聚类, 关联规则发现等算法
- **机器学习**: 利用经验, 通过计算, 构建模型, 来改善系统自身性能.
经验: 认为的, 报告调参, 特征选择, 模型选择是通过博士, 大牛或者总监开会得出.
计算: 一种是计算平台, 包括大数据Hadoop或者 Spark, tf 等. 另一种是计算模型RF, xgb
构建模型: 基本的5步骤
算法本身就是设定一个计算程序可以自主学习任务T的经验E, 使得该程序逐步提高.
- **属性(特征)**: 描述食物在特定方面的性质的事项
   属性值: 属性上的取值.
   属性空间(输入空间): 由属性张成的空间, 属性空间 $x$.
- 记录（样本）: 一个具体事物的属性描述, 由属性向量表示, 第$j$个记录$x_j$的属性向量

$$x_j = (x_j^{(1)}, x_j^{(2)}, ... , x_j^{(i)}, x_j^{(n)})^T , j = 1,2, ... N;    x_j \epsilon \chi$$

- **标记**:描述事物某个特征的事项.
  标记值: 标记上的取值.
  标记空间（输出空间）: 所有标记的集合， 标记空间 $Y$.
  
- **数据集**:

  记录的集合(无监督)，$ D = {x_1, x_2, .... , x_N};$

  样例的集合(有监督), $ D = {(x_1, y_1), (x_2, y_2), .... , (x_N, y_N)};$
  
- 回归: 有监督学习中，标记为连续值, $y=R$
  分类: 有监督学习中，标记为离散值，其中  $|y| = 2, y ={0, 1}或y= {+1, -1}为二分类; |y| > 2, y+{c_1, c_2, ... ,c_n} 为多分类$
  
- 流出法: 将数据集D 划分为两个互斥的集合，其中一个集合作为训练集，另一个作为测试集合. 在训练模型，在测试集上测试误差，作为对泛华能力的评估.

- 训练数据集: 用以训练模型的数据集的子集， $D_traing \in D$

  测试数据集: 应用测试模型的数据集的子集， $D_testing \in D$
  
$$
线性回归的目标函数为:
   J(\theta) = \frac{1}{2}\sum_{i=1}^m(h_{\theta}(x^{(i)}) - y^{(i)})^2
$$

$$
将目标函数增加平方和损失:
   J(\theta) = \frac{1}{2}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda \displaystyle \theta_j^2
$$

### 假设空间和参数空间

- 决策函数(非概率模型):  从输入空间 $X$ 到输出空间$Y$ 的映射 $f$ : $X \to Y $

  假设空间 $F$  定义为决策函数的集合

  ​						$$F = \{f|Y = f(X)\}$$

- 假设空间 $F$ 也可以定义为条件概率的集合(概率模型)

  ​						$$ F = \{P|P(Y|X)\}$$

  其中 $X$ 是定义在输入空间 $X$ 上的随机变量，Y是定义在输出空间Y 上的随机变量

### 模型策略

- 损失函数（代价函数）度量模型预测错误的程度，是预测输出$f(X)$和实际输出$Y$的非负实际函数，记为:

- 0-1 损失函数

- 平方损失函数

- 绝对损失函数

- 对数似然损失函数

- 经验风险(经验损失)的模型$f(X)关于训练数据集$

  平均损失

- 经验风险最小化
- 过拟合
- 欠拟合
- 泛华能力
- 结构风险
- 结构风险最小化
- 正则化项可以是参数向量的$L_2$范数

### 优化算法

- 机器学习的训练过程就是使用训练数据集$D$, 按照学习准则在假设空间$F$中寻找最优模型$f^*$d的最优化求解过程

  $$$$

  或者在参数空间中寻找最优参数$w^*$的最优化求解过程

  $$$$

- 梯度下降法: 通过迭代的方法来计算训练集$D$上的风险函数最小值

  $$$$

  其中， $w_t$为第$t$次迭代的参数值，$\alpha$ 为学习率

### 性能量度与评估方法

分类中，模型的预测结果分为:

1. 真正列(True  Positive, TP) : 将正类预测为正类;

2. 假负类(False Negative, FN):  将正类预测为负类;

3. 假正类(False Positive, FP):  将负类预测为正类;

4. 正真类(True Negative, TN): 将负类预测为负类;

   |      | Positive | Negtive |
   | ---- | -------- | ------- |
   | 正   | TP       | FN      |
   | 负   | FP       | TN      |

   精确率(查准率)

   召回率(查全率)
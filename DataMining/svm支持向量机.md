# svm 支持向量机

## SVM定义和原理

1. 定义

   > 支持向量机(Support Vector Machine) 是一个监督学习算法，既可以用来分类问题也可以用于回归问题, 主要用于分类问题中, 在svm 算法中， 我们将数据绘制在n维空间中(n代表数据的特征数)， 每个特征的值都是特定坐标的值，SVM 是将样本分成两类的最佳超平面。

   ![](/home/pawn/work/accumulation/DataMining/data/svm.jpg)

## 理解拉格朗日乘子法

[传送门](https://www.matongxue.com/madocs/939.html)

1. 定义

   > 要求函数 $f$ 在 $g$  约束下的极值这种问题可以表示为:

   $$
   minmax f \\
   s.t.g= 0
   $$

   $s.t.$意思是subject to, 服从于, 约束于的意思。

   可以列出方程组求解:
   $$
   \begin{cases}
   \nabla f = \lambda\nabla g \\
   g = 0
   \end{cases}
   $$
   

## 核函数

1. 定义
   - 核函数是特征转换函数
   - 常用的核函数一般和应用场景相关, 在不同领域所应用的核函数可能也不相同。但是实际上也有一些通用的核函数: 多项式核函数，高斯核函数
2.  核函数的对比:
   -  线性核函数: 这是最简单的核函数， 它直接计算两个输入特征向量的内积
     - 优点: 简单高效， 结果易解释， 总能生成一个最简洁的线性分割超平面
     - 缺点: 只适合线性可分的数据集
   - 多项式核函数: 通过多项式来作为特征映射函数
     - 优点: 可以拟合出复杂的分割超平面。
     - 缺点: 参数太多。有Y,c,n 三个参数要选择， 选择起来比较困难；另外多项式的阶数不宜太高否则会给模型求解带来困难
3. 高斯核函数
   - 优点: 可以把特征映射到无限多维，并且没有多项式计算那么困难，参与也比较好选择。
   - 缺点:不容易解释，计算速度比较慢，容易过拟合。

